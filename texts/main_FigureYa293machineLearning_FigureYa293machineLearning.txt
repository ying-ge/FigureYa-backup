FigureYa293machineLearningV2
FigureYa293machineLearningV2
Author(s)
: Guoqi Li; Yasi Zhang
Reviewer(s)
: Ying Ge
Date
: 2025-05-20
Academic Citation
If you use this code in your work or research, we kindly request that
you cite our publication:
Xiaofan Lu, et al. (2025). FigureYa: A Standardized Visualization
Framework for Enhancing Biomedical Data Interpretation and Research
Efficiency. iMetaMed.
https://doi.org/10.1002/imm3.70005
需求描述
Demand description
这个文章里比较不同的模型放在一个图，以及比较不同的算法放在一个图。
In this article, different models are compared in one graph, and
different algorithms are compared in another graph.
出自
https://www.nature.com/articles/s41467-022-28421-6
图2 通过基于机器学习的整合流程，开发并验证了一种共识性IRLS模型。 A
在LOOCV框架下构建了共计101种预测模型，并计算了各模型在所有验证数据集中的C指数。
B 在TCGA-CRC队列（n =
584）中，当偏似然偏差达到最小值时确定最优λ值，并进一步生成最具预后价值基因的Lasso系数。数据以均值±95%置信区间[CI]表示。
C 逐步Cox回归最终获得的16个lncRNA系数。 D–K
基于IRLS的TCGA-CRC患者总生存期（OS）Kaplan-Meier曲线（对数秩检验：P =
9.16e−19）。
Source:
https://www.nature.com/articles/s41467-022-28421-6
Fig. 2 A consensus IRLS was developed and validated via the machine
learning-based integrative procedure. A A total of 101 kinds of
prediction models via LOOCV framework and further calculated the C-index
of each model across all validation datasets. B In the TCGA-CRC cohort
(n = 584), the determination of the optimal λ was obtained when the
partial likelihood deviance reached the minimum value, and further
generated Lasso coefficients of the most useful prognostic genes. Data
are presented as mean ± 95% confidence interval [CI]. C Coefficients of
16 lncRNAs finally obtained in stepwise. Cox regression. D–K
Kaplan–Meier curves of OS according to the IRLS in TCGA-CRC (log-rank
test: P = 9.16e−19).
应用场景
Application scenarios
基于这10种算法的组合去构建模型，会受到输入数据集的基因数目和质量的影响。
因此，基于不同的基因，有些模型可能得不到特征而出现报错的现象，这属于正常现象。
最后的result都会有结果，但是得到结果会有变化，以及有些模型（指单一模型）或模型组合（指组合模型）预测效能的C指数为0.5，这些模型都是未得到结果的模型（根本原因是输入数据中基因的问题），所以可以调整输入数据的基因来获取更多有结果的模型组合结果。
例文当中有些Figure的画法可参考FigureYa：
Figure
1，FigureYa69cancerSubtype、FigureYa71ssGSEA、FigureYa55panCancer_violin、FigureYa15WGCNA、FigureYa170ImmuLncRNA
Figure
2，FigureYa293machineLearning、FigureYa31lasso、FigureYa35batch_bestSeparation
Figure 3，FigureYa189timeCindex、FigureYa220repeatedLasso
Figure 5，FigureYa90subgroup
Figure 6，FigureYa105GDSC
Figure 7，FigureYa71ssGSEA、FigureYa152DouleCorPlot
The performance of models built using these 10 algorithms in
combination is influenced by the number and quality of genes in the
input dataset.
Therefore, depending on the genes used, some models may fail to
extract features and return errors—this is a normal occurrence.
All final results will be generated, but the outcomes may vary.
Additionally, some models (single models) or model combinations
(ensemble models) may yield a C-index of 0.5, indicating that they
failed to produce meaningful results (primarily due to issues with the
input gene data). To obtain more valid model combinations, adjusting the
input gene set may help.
For reference on figure design, you may consult FigureYa:
Figure
1，FigureYa69cancerSubtype、FigureYa71ssGSEA、FigureYa55panCancer_violin、FigureYa15WGCNA、FigureYa170ImmuLncRNA
Figure
2，FigureYa293machineLearning、FigureYa31lasso、FigureYa35batch_bestSeparation
Figure 3，FigureYa189timeCindex、FigureYa220repeatedLasso
Figure 5，FigureYa90subgroup
Figure 6，FigureYa105GDSC
Figure 7，FigureYa71ssGSEA、FigureYa152DouleCorPlotexamples.
环境设置
Environment Setup
source("install_dependencies.R")
library(survival)
library(randomForestSRC)
library(glmnet)
library(plsRcox)
library(superpc)
library(gbm)
library(CoxBoost)
library(survivalsvm)
library(dplyr)
library(tibble)
library(BART)
library(miscTools)
library(compareC)
library(ggplot2)
library(ggsci)
library(tidyr)
library(ggbreak)
# 显示英文报错信息
# Show English error messages
Sys.setenv(LANGUAGE = "en") 

# 禁止chr转成factor
# Prevent character-to-factor conversion
options(stringsAsFactors = FALSE)
输入文件
Input Files
TCGA.txt，GSE57303.txt，GSE62254.txt，数据集。行为样本，第一列为样本名，第二三列为生存时间和生存状态，后面的列均为基因。
TCGA.txt, GSE57303.txt, GSE62254.txt, datasets. Rows represent
samples, with the first column being sample names, the second and third
columns being survival time and survival status, and the remaining
columns all being genes.
# 加载数据集
# Load datasets
tcga <- read.table("TCGA.txt", header = T,sep = "\t", quote = "", check.names = F)
GSE57303 <- read.table("GSE57303.txt", header = T, sep = "\t", quote = "", check.names = F)
GSE62254 <- read.table("GSE62254.txt", header = T, sep = "\t", quote = "", check.names = F)

# 生成包含三个数据集的列表
# Create a list containing the three datasets
mm <- list(TCGA = tcga,
           GSE57303 = GSE57303, GSE62254 = GSE62254)

# 数据标准化
# Data standardization
mm <- lapply(mm,function(x){
  x[,-c(1:3)] <- scale(x[,-c(1:3)])
  return(x)})

result <- data.frame()

# TCGA作为训练集
# Use TCGA as the training set
est_data <- mm$TCGA

# GEO作为验证集
# Use GEO as the validation set
val_data_list <- mm

pre_var <- colnames(est_data)[-c(1:3)]
est_dd <- est_data[, c('OS.time', 'OS', pre_var)]
val_dd_list <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', pre_var)]})

# 设置种子数和节点数，其中节点数可以调整
# Set the seed number and node size (node size can be adjusted)
rf_nodesize <- 5
seed <- 123
下面开始实现10种方法：
Below starts the implementation of 10 methods:
1.RSF
cv.res <- cv.CoxBoost(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1, 2)]), 
                      maxstepno = 500, K = 10, type = "verweij",  penalty = pen$penalty)
fit <- CoxBoost(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1, 2)]), 
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, newdata = x[, -c(1, 2)], newtime = x[, 1],  newstatus = x[, 2], type = "lp")))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('RSF + CoxBoost')
result <- rbind(result, cc)

## 1-3.RSF + Enet
set.seed(seed)
fit <- rfsrc(Surv(OS.time, OS)~., data = est_dd, 
             ntree = 1000, nodesize = rf_nodesize, 
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)

vimp_result <- vimp(fit, importance = "permute")  
importance_scores <- vimp_result$importance
rid <- names(sort(importance_scores, decreasing = TRUE))  

# 3. 筛选重要变量（例如保留重要性 > 0 的变量）
# Filter important variables (e.g. keep those with importance > 0)
rid <- rid[importance_scores[rid] > 0] 

est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
x1 <- as.matrix(est_dd2[, rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
for (alpha in seq(0.1, 0.9, 0.1)) {
  set.seed(seed)
  fit = cv.glmnet(x1, x2, family = "cox", alpha = alpha, nfolds = 10)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'link', newx = as.matrix(x[, -c(1, 2)]), s = fit$lambda.min)))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('RSF + ', 'Enet', '[α=', alpha, ']')
  result <- rbind(result, cc)
  }

## 1-4.RSF + GBM
set.seed(seed)
fit <- rfsrc(Surv(OS.time, OS)~., data = est_dd,
             ntree = 1000, nodesize = rf_nodesize,  
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)

vimp_result <- vimp(fit, importance = "permute")  
importance_scores <- vimp_result$importance
rid <- names(sort(importance_scores, decreasing = TRUE))  

# 3. 筛选重要变量（例如保留重要性 > 0 的变量）
# Filter important variables (e.g. keep those with importance > 0)
rid <- rid[importance_scores[rid] > 0] 

est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
set.seed(seed)
fit <- gbm(formula = Surv(OS.time, OS)~., data = est_dd2, distribution = 'coxph',
                         n.trees = 10000,
                         interaction.depth = 3,
                         n.minobsinnode = 10,
                         shrinkage = 0.001,
                         cv.folds = 10, n.cores = 6)

best <- which.min(fit$cv.error)
set.seed(seed)
fit <- gbm(formula = Surv(OS.time,OS)~., data = est_dd2, distribution = 'coxph',
           n.trees = best,
           interaction.depth = 3,
           n.minobsinnode = 10,
           shrinkage = 0.001,
           cv.folds = 10,n.cores = 8)
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, x, n.trees = best, type = 'link')))})
cc <- data.frame(Cindex=sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('RSF + ', 'GBM')
result <- rbind(result, cc)

## 1-5.RSF + Lasso
set.seed(seed)
fit <- rfsrc(Surv(OS.time, OS)~., data = est_dd,
             ntree = 1000, nodesize = rf_nodesize, 
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)


vimp_result <- vimp(fit, importance = "permute")  
importance_scores <- vimp_result$importance
rid <- names(sort(importance_scores, decreasing = TRUE))  

# 3. 筛选重要变量（例如保留重要性 > 0 的变量）
# Filter important variables (e.g. keep those with importance > 0)
rid <- rid[importance_scores[rid] > 0] 

est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
x1 <- as.matrix(est_dd2[, rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1, 2)]), s = fit$lambda.min)))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('RSF + ', 'Lasso')
result <- rbind(result, cc)

## 1-6.RSF + plsRcox
set.seed(seed)
fit <- rfsrc(Surv(OS.time, OS)~., data = est_dd,
             ntree = 1000, nodesize = rf_nodesize, 
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)

vimp_result <- vimp(fit, importance = "permute") 
importance_scores <- vimp_result$importance
rid <- names(sort(importance_scores, decreasing = TRUE))  

# 3. 筛选重要变量（例如保留重要性 > 0 的变量）
# Filter important variables (e.g. keep those with importance > 0)
rid <- rid[importance_scores[rid] > 0] 

est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
set.seed(seed)
cv.plsRcox.res = cv.plsRcox(list(x = est_dd2[, rid], time = est_dd2$OS.time, status = est_dd2$OS), nt = 10, verbose = FALSE)
fit <- plsRcox(est_dd2[, rid], time = est_dd2$OS.time, event = est_dd2$OS, nt = as.numeric(cv.plsRcox.res[5]))
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = "lp", newdata = x[, -c(1, 2)])))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('RSF + ', 'plsRcox')
result <- rbind(result, cc)

## 1-7.RSF + Ridge
set.seed(seed)
fit <- rfsrc(Surv(OS.time, OS)~., data = est_dd, 
             ntree = 1000, nodesize = rf_nodesize,
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)

vimp_result <- vimp(fit, importance = "permute") 
importance_scores <- vimp_result$importance
rid <- names(sort(importance_scores, decreasing = TRUE))  

# 3. 筛选重要变量（例如保留重要性 > 0 的变量）
# Filter important variables (e.g. keep those with importance > 0)
rid <- rid[importance_scores[rid] > 0] 

est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
x1 <- as.matrix(est_dd2[, rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold=10, 
                family = "binomial", alpha = 0,
                type.measure = "class")
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1, 2)]), s = fit$lambda.min)))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('RSF + ', 'Ridge')
result <- rbind(result, cc)

## 1-8.RSF + StepCox
set.seed(seed)
fit <- rfsrc(Surv(OS.time,OS)~., data = est_dd,
             ntree = 1000, nodesize = rf_nodesize, 
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)

vimp_result <- vimp(fit, importance = "permute")  
importance_scores <- vimp_result$importance
rid <- names(sort(importance_scores, decreasing = TRUE))  

# 3. 筛选重要变量（例如保留重要性 > 0 的变量）
# Filter important variables (e.g. keep those with importance > 0)
rid <- rid[importance_scores[rid] > 0] 

est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
for (direction in c("both", "backward", "forward")) {
  fit <- step(coxph(Surv(OS.time, OS)~., est_dd2), direction = direction)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS=predict(fit, type = 'risk', newdata = x))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('RSF + ', 'StepCox', '[', direction, ']')
  result <- rbind(result, cc)
  }
2.Enet
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
for (alpha in seq(0.1, 0.9, 0.1)) {
  set.seed(seed)
  fit = cv.glmnet(x1, x2, family = "cox", alpha = alpha, nfolds = 10)
  rs <- lapply(val_dd_list,function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit,type = 'link', newx = as.matrix(x[,-c(1,2)]), s = fit$lambda.min)))})
  cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('Enet', '[α=', alpha, ']')
  result <- rbind(result, cc)
  }
3.StepCox
for (direction in c("both", "backward", "forward")) {
  fit <- step(coxph(Surv(OS.time,OS)~., est_dd), direction = direction)
  rs <- lapply(val_dd_list,function(x){cbind(x[, 1:2], RS = predict(fit, type = 'risk', newdata = x))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']')
  result <- rbind(result, cc)
  }
for (direction in c("both", "backward", "forward")) {
  fit <- step(coxph(Surv(OS.time, OS)~., est_dd), direction = direction)
  rid <- names(coef(fit))#这里不用卡P值，迭代的结果就是可以纳入的基因
  est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
  val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
  set.seed(seed)
  pen <- optimCoxBoostPenalty(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1,2)]),
                              trace=TRUE, start.penalty = 500, parallel = T)
  cv.res <- cv.CoxBoost(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1,2)]),
                        maxstepno = 500, K = 10 , type = "verweij", penalty = pen$penalty)
  fit <- CoxBoost(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1, 2)]),
                  stepno = cv.res$optimal.step, penalty = pen$penalty)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, newdata = x[, -c(1, 2)], newtime=x[, 1], newstatus=x[,2], type="lp")))})
  cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + CoxBoost')
  result <- rbind(result, cc)
  x1 <- as.matrix(est_dd2[, rid])
  x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
  for (alpha in seq(0.1, 0.9, 0.1)) {
    set.seed(seed)
    fit = cv.glmnet(x1, x2, family = "cox",alpha = alpha, nfolds = 10)
    rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'link', newx = as.matrix(x[, -c(1, 2)]), s = fit$lambda.min)))})
    cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
      rownames_to_column('ID')
    cc$Model <- paste0('StepCox', '[', direction, ']', ' + Enet', '[α=', alpha, ']')
    result <- rbind(result, cc)
    }
  set.seed(seed)
  fit <- gbm(formula = Surv(OS.time, OS)~., data = est_dd2, distribution = 'coxph',
             n.trees = 10000,
             interaction.depth = 3,
             n.minobsinnode = 10,
             shrinkage = 0.001,
             cv.folds = 10,n.cores = 6)
  
  # 找到具有最小交叉验证误差的树数量索引
  # find index for number trees with minimum CV error
  best <- which.min(fit$cv.error)
  
  set.seed(seed)
  fit <- gbm(formula = Surv(OS.time, OS)~., data = est_dd2, distribution = 'coxph',
             n.trees = best,
             interaction.depth = 3,
             n.minobsinnode = 10,
             shrinkage = 0.001,
             cv.folds = 10,n.cores = 8)
  rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, x, n.trees = best, type = 'link')))})
  cc <- data.frame(Cindex=sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + GBM')
  result <- rbind(result, cc)
  x1 <- as.matrix(est_dd2[, rid])
  x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
  set.seed(seed)
  fit = cv.glmnet(x1, x2,
                  nfold=10, #例文描述：10-fold cross-validation
                  family = "binomial", alpha = 1,
                  type.measure = "class")
  rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1, 2)]), s = fit$lambda.min)))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + Lasso')
  result <- rbind(result, cc)
  set.seed(seed)
  cv.plsRcox.res = cv.plsRcox(list(x = est_dd2[,rid], time = est_dd2$OS.time, status = est_dd2$OS), nt = 10, verbose = FALSE)
  fit <- plsRcox(est_dd2[, rid], time = est_dd2$OS.time,
                 event = est_dd2$OS, nt = as.numeric(cv.plsRcox.res[5]))
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = "lp", newdata = x[, -c(1,2)])))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + plsRcox')
  result <- rbind(result, cc)
  x1 <- as.matrix(est_dd2[, rid])
  x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
  set.seed(seed)
  fit = cv.glmnet(x1, x2,
                  nfold = 10, #例文描述：10-fold cross-validation
                  family = "binomial", alpha = 0,
                  type.measure = "class")
  rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1, 2)]), s = fit$lambda.min)))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + Ridge')
  result <- rbind(result, cc)
  set.seed(seed)
  fit <- rfsrc(Surv(OS.time,OS)~., data = est_dd2,
               ntree = 1000, nodesize = rf_nodesize, #该值建议多调整
               splitrule = 'logrank',
               importance = T,
               proximity = T,
               forest = T,
               seed = seed)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = predict(fit, newdata = x)$predicted)})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + RSF')
  result <- rbind(result, cc)
  data <- list(x = t(est_dd2[, -c(1, 2)]), y = est_dd2$OS.time,
               censoring.status = est_dd2$OS,
               featurenames = colnames(est_dd2)[-c(1,2)])
  set.seed(seed)
  fit <- superpc.train(data = data,type = 'survival', s0.perc = 0.5) #default
  cv.fit <- superpc.cv(fit, data, n.threshold = 20, #default
                       n.fold = 10,
                       n.components = 3,
                       min.features = 5,
                       max.features = nrow(data$x),
                       compute.fullcv = TRUE,
                       compute.preval = TRUE)
  rs <- lapply(val_dd_list2, function(w){
    test <- list(x = t(w[, -c(1,2)]), y = w$OS.time, censoring.status = w$OS, featurenames = colnames(w)[-c(1,2)])
    ff <- superpc.predict(fit, data, test, threshold = cv.fit$thresholds[which.max(cv.fit[["scor"]][1,])], n.components = 1)
    rr <- as.numeric(ff$v.pred)
    rr2 <- cbind(w[,1:2], RS = rr)
    return(rr2)
    })
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + SuperPC')
  result <- rbind(result, cc)
  fit = survivalsvm(Surv(OS.time,OS)~., data = est_dd2, gamma.mu = 1)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, x)$predicted))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('StepCox', '[', direction, ']', ' + survival-SVM')
  result <- rbind(result, cc)
  }
4.CoxBoost
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]), maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rs <- lapply(val_dd_list, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, newdata = x[, -c(1,2)], newtime = x[,1], newstatus = x[,2], type = "lp")))})
cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost')
result <- rbind(result, cc)

## 4-2.CoxBoost + Enet
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                            trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                      maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)`!=0), "id"]
est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
x1 <- as.matrix(est_dd2[, rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
for (alpha in seq(0.1, 0.9, 0.1)) {
  set.seed(seed)
  fit = cv.glmnet(x1, x2, family = "cox", alpha = alpha, nfolds = 10)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'link', newx = as.matrix(x[, -c(1,2)]), s = fit$lambda.min)))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('CoxBoost', ' + Enet', '[α=', alpha, ']')
  result <- rbind(result, cc)
  }

## 4-3.CoxBoost + GBM
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                          trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                    maxstepno = 500, K= 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                              stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)`!=0), "id"]
est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
set.seed(seed)
fit <- gbm(formula = Surv(OS.time,OS)~., data = est_dd2, distribution = 'coxph',
           n.trees = 10000,
           interaction.depth = 3,
           n.minobsinnode = 10,
           shrinkage = 0.001,
           cv.folds = 10, n.cores = 6)

# 找到具有最小交叉验证误差的树数量索引
# find index for number trees with minimum CV error
best <- which.min(fit$cv.error)

set.seed(seed)
fit <- gbm(formula = Surv(OS.time,OS)~., data = est_dd2, distribution = 'coxph',
           n.trees = best,
           interaction.depth = 3,
           n.minobsinnode = 10,
           shrinkage = 0.001,
           cv.folds = 10,n.cores = 8)
rs <- lapply(val_dd_list2,function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, x, n.trees = best, type = 'link')))})
cc <- data.frame(Cindex=sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost + ', 'GBM')
result <- rbind(result, cc)

## 4-4.CoxBoost + Lasso
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                          trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                    maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                              stepno=cv.res$optimal.step, penalty=pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)` != 0), "id"]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
x1 <- as.matrix(est_dd2[, rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1,2)]), s = fit$lambda.min)))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost + ', 'Lasso')
result <- rbind(result, cc)

## 4-5.CoxBoost + plsRcox
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                          trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                    maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                              stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)` != 0), "id"]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
set.seed(seed)
cv.plsRcox.res = cv.plsRcox(list(x = est_dd2[,rid], time = est_dd2$OS.time, status = est_dd2$OS), nt = 10, verbose = FALSE)
fit <- plsRcox(est_dd2[, rid], time = est_dd2$OS.time, event = est_dd2$OS, nt = as.numeric(cv.plsRcox.res[5]))
rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, type="lp", newdata = x[, -c(1,2)])))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost + ', 'plsRcox')
result <- rbind(result, cc)

## 4-6.CoxBoost + Ridge
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                          trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                      maxstepno = 500, K=10, type="verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)` != 0), "id"]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
x1 <- as.matrix(est_dd2[, rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold=10, 
                family = "binomial", alpha = 0,
                type.measure = "class")
rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1,2)]), s = fit$lambda.min)))})
cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost + ', 'Ridge')
result <- rbind(result, cc)

## 4-7.CoxBoost + StepCox
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                          trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                                    maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                              stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)` != 0), "id"]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
for (direction in c("both", "backward", "forward")) {
  fit <- step(coxph(Surv(OS.time,OS)~., est_dd2), direction = direction)
  rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = predict(fit, type = 'risk', newdata = x))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('CoxBoost + ', 'StepCox', '[', direction, ']')
  result <- rbind(result, cc)
  }
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[,-c(1,2)]),
                      maxstepno = 500, K= 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[,-c(1,2)]),
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)` != 0), "id"]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
data <- list(x = t(est_dd2[, -c(1,2)]), y = est_dd2$OS.time, censoring.status = est_dd2$OS,
             featurenames = colnames(est_dd2)[-c(1,2)])
set.seed(seed)
fit <- superpc.train(data = data, type = 'survival', s0.perc = 0.5) #default
cv.fit <- superpc.cv(fit, data, n.threshold = 20, #default
                     n.fold = 10,
                     n.components = 3,
                     min.features = 5,
                     max.features = nrow(data$x),
                     compute.fullcv = TRUE,
                     compute.preval =TRUE)
rs <- lapply(val_dd_list2, function(w){
  test <- list(x=t(w[, -c(1,2)]), y = w$OS.time, censoring.status = w$OS, featurenames = colnames(w)[-c(1,2)])
  ff <- superpc.predict(fit, data, test, threshold = cv.fit$thresholds[which.max(cv.fit[["scor"]][1,])], n.components = 1)
  rr <- as.numeric(ff$v.pred)
  rr2 <- cbind(w[,1:2], RS = rr)
  return(rr2)
  })
cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost + ', 'SuperPC')
result <- rbind(result, cc)

## 4-9.CoxBoost + survival-SVM
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                            trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[, -c(1,2)]),
                      maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd[, 'OS.time'], est_dd[, 'OS'], as.matrix(est_dd[,-c(1,2)]),
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rid <- as.data.frame(coef(fit))
rid$id <- rownames(rid)
rid <- rid[which(rid$`coef(fit)` != 0), "id"]
est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
fit = survivalsvm(Surv(OS.time, OS)~., data = est_dd2, gamma.mu = 1)
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, x)$predicted))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('CoxBoost + ', 'survival-SVM')
result <- rbind(result, cc)
5.plsRcox
set.seed(seed)
cv.plsRcox.res = cv.plsRcox(list(x = est_dd[,pre_var], time = est_dd$OS.time, status = est_dd$OS), nt = 10, verbose = FALSE)
fit <- plsRcox(est_dd[,pre_var], time = est_dd$OS.time, event = est_dd$OS, nt = as.numeric(cv.plsRcox.res[5]))
rs <- lapply(val_dd_list, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit,type = "lp", newdata = x[, -c(1, 2)])))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time,OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('plsRcox')
result <- rbind(result, cc)
6.superpc
data <- list(x = t(est_dd[, -c(1,2)]), y = est_dd$OS.time, censoring.status = est_dd$OS, featurenames = colnames(est_dd)[-c(1, 2)])
set.seed(seed) 
fit <- superpc.train(data = data,type = 'survival', s0.perc = 0.5) 
cv.fit <- superpc.cv(fit, data, n.threshold = 20, 
                     n.fold = 10,
                     n.components = 3,
                     min.features = 5,
                     max.features = nrow(data$x),
                     compute.fullcv = TRUE,
                     compute.preval = TRUE)
rs <- lapply(val_dd_list, function(w){
  test <- list(x = t(w[,-c(1,2)]), y = w$OS.time, censoring.status = w$OS, featurenames = colnames(w)[-c(1,2)])
  ff <- superpc.predict(fit, data, test, threshold = cv.fit$thresholds[which.max(cv.fit[["scor"]][1,])], n.components = 1)
  rr <- as.numeric(ff$v.pred)
  rr2 <- cbind(w[,1:2], RS = rr)
  return(rr2)
  })
cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('SuperPC')
result <- rbind(result, cc)
7.GBM
set.seed(seed)
fit <- gbm(formula = Surv(OS.time,OS)~., data = est_dd, distribution = 'coxph',
           n.trees = 10000,
           interaction.depth = 3,
           n.minobsinnode = 10,
           shrinkage = 0.001,
           cv.folds = 10, n.cores = 6)

# 找到具有最小交叉验证误差的树数量索引
# find index for number trees with minimum CV error
best <- which.min(fit$cv.error)

set.seed(seed)
fit <- gbm(formula = Surv(OS.time, OS)~., data = est_dd, distribution = 'coxph',
           n.trees = best,
           interaction.depth = 3,
           n.minobsinnode = 10,
           shrinkage = 0.001,
           cv.folds = 10, n.cores = 8)
rs <- lapply(val_dd_list,function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, x, n.trees = best, type = 'link')))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('GBM')
result <- rbind(result, cc)
8.survivalsvm
fit = survivalsvm(Surv(OS.time,OS)~., data = est_dd, gamma.mu = 1)
rs <- lapply(val_dd_list, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, x)$predicted))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('survival - SVM')
result <- rbind(result, cc)
9.Ridge
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = glmnet(x1, x2, family = "binomial", alpha = 0, lambda = NULL)
cvfit = cv.glmnet(x1, x2,
                  nfold = 10, 
                  family = "binomial",
                  type.measure = "class"
)

rs <- lapply(val_dd_list, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1,2)]), s = cvfit$lambda.min)))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time,OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Ridge')
result <- rbind(result, cc)
10.Lasso
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
rs <- lapply(val_dd_list, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[, -c(1,2)]), s = fit$lambda.min)))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso')
result <- rbind(result, cc)

## 10.1.Lasso + CoxBoost
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10,
                family = "cox", alpha = 1)
fit$lambda.min
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid <- rid[-1]
est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
set.seed(seed)
pen <- optimCoxBoostPenalty(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1,2)]),
                            trace = TRUE, start.penalty = 500, parallel = T)
cv.res <- cv.CoxBoost(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1,2)]),
                      maxstepno = 500, K = 10, type = "verweij", penalty = pen$penalty)
fit <- CoxBoost(est_dd2[, 'OS.time'], est_dd2[, 'OS'], as.matrix(est_dd2[, -c(1,2)]),
                stepno = cv.res$optimal.step, penalty = pen$penalty)
rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, newdata = x[,-c(1,2)], newtime = x[,1], newstatus = x[,2], type = "lp")))})
cc <- data.frame(Cindex=sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso + CoxBoost')
result <- rbind(result, cc)

## 10.2.Lasso + GBM
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
fit$lambda.min
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid <- rid[-1]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
set.seed(seed)
fit <- gbm(formula = Surv(OS.time,OS)~., data = est_dd2, distribution = 'coxph',
                         n.trees = 10000,
                         interaction.depth = 3,
                         n.minobsinnode = 10,
                         shrinkage = 0.001,
                         cv.folds = 10, n.cores = 6)

# 找到具有最小交叉验证误差的树数量索引
# find index for number trees with minimum CV error
best <- which.min(fit$cv.error)

set.seed(seed)
fit <- gbm(formula = Surv(OS.time,OS)~., data = est_dd2, distribution = 'coxph',
           n.trees = best,
           interaction.depth = 3,
           n.minobsinnode = 10,
           shrinkage = 0.001,
           cv.folds = 10, n.cores = 8)
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, x, n.trees = best, type = 'link')))})
cc <- data.frame(Cindex = sapply(rs,function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])}))%>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso + ', 'GBM')
result <- rbind(result, cc)

## 10.3.Lasso + plsRcox
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
fit$lambda.min
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid <- rid[-1]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
set.seed(seed)
cv.plsRcox.res = cv.plsRcox(list(x = est_dd2[, rid], time = est_dd2$OS.time, status = est_dd2$OS), nt = 10, verbose = FALSE)
fit <- plsRcox(est_dd2[, rid], time = est_dd2$OS.time, event = est_dd2$OS, nt = as.numeric(cv.plsRcox.res[5]))
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = as.numeric(predict(fit, type = "lp", newdata = x[,-c(1,2)])))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso + ', 'plsRcox')
result <- rbind(result, cc)

## 10.4.Lasso + RSF
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
fit$lambda.min
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid<-rid[-1]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
set.seed(seed)
fit <- rfsrc(Surv(OS.time,OS)~., data = est_dd2,
             ntree = 1000, nodesize = rf_nodesize, 
             splitrule = 'logrank',
             importance = T,
             proximity = T,
             forest = T,
             seed = seed)
rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = predict(fit, newdata = x)$predicted)})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso', ' + RSF')
result <- rbind(result, cc)

## 10.5.Lasso + stepcox
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
fit$lambda.min
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid <- rid[-1]
est_dd2 <- est_data[, c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
for (direction in c("both", "backward", "forward")) {
  fit <- step(coxph(Surv(OS.time,OS)~., est_dd2), direction = direction)
  rs <- lapply(val_dd_list2, function(x){cbind(x[, 1:2], RS = predict(fit, type = 'risk', newdata = x))})
  cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
    rownames_to_column('ID')
  cc$Model <- paste0('Lasso + ', 'StepCox', '[', direction, ']')
  result <- rbind(result, cc)
  }
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid <- rid[-1]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[, c('OS.time', 'OS', rid)]})
data <- list(x = t(est_dd2[,-c(1,2)]), y = est_dd2$OS.time, censoring.status = est_dd2$OS,
                           featurenames = colnames(est_dd2)[-c(1,2)])
set.seed(seed)
fit <- superpc.train(data = data,type = 'survival', s0.perc = 0.5) 
cv.fit <- superpc.cv(fit,data,n.threshold = 20, 
                     n.fold = 10,
                     n.components = 3,
                     min.features = 5,
                     max.features = nrow(data$x),
                     compute.fullcv = TRUE,
                     compute.preval = TRUE)
rs <- lapply(val_dd_list2, function(w){
  test <- list(x = t(w[,-c(1,2)]), y = w$OS.time, censoring.status = w$OS, featurenames = colnames(w)[-c(1,2)])
  ff <- superpc.predict(fit, data, test, threshold = cv.fit$thresholds[which.max(cv.fit[["scor"]][1,])], n.components = 1)
  rr <- as.numeric(ff$v.pred)
  rr2 <- cbind(w[, 1:2], RS = rr)
  return(rr2)
  })
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso + ', 'SuperPC')
result <- rbind(result, cc)

## 10.7.Lasso + survival-SVM
x1 <- as.matrix(est_dd[, pre_var])
x2 <- as.matrix(Surv(est_dd$OS.time, est_dd$OS))
set.seed(seed)
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")
fit$lambda.min
myCoefs <- coef(fit, s = "lambda.min");
rid <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
rid <- rid[-1]
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})
fit = survivalsvm(Surv(OS.time,OS)~., data = est_dd2, gamma.mu = 1)
rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, x)$predicted))})
cc <- data.frame(Cindex = sapply(rs, function(x){as.numeric(summary(coxph(Surv(OS.time, OS) ~ RS, x))$concordance[1])})) %>%
  rownames_to_column('ID')
cc$Model <- paste0('Lasso + ', 'survival-SVM')
result <- rbind(result, cc)

# 将得到的结果赋给result2变量进行操作
# Assign the obtained results to variable result2 for processing
result2 <- result %>%
  group_by(Model, ID) %>%
  summarise(Cindex = mean(Cindex), .groups = "drop")

### 将结果的长数据转换为宽数据
### Convert long format results to wide format
dd2 <- pivot_wider(result2, names_from = 'ID', values_from = 'Cindex') %>% as.data.frame()

# 将C指数定义为数值型
# Define C-index as numeric type
dd2[,-1] <- apply(dd2[,-1], 2, as.numeric)

# 求每个模型的C指数在三个数据集的均值
# Calculate mean C-index across three datasets for each model
dd2$All <- apply(dd2[,2:4], 1, mean)

# 求每个模型的C指数在GEO验证集的均值
# Calculate mean C-index in GEO validation sets for each model
dd2$GEO <- apply(dd2[,3:4], 1, mean)

###查看每个模型的C指数
### View C-index for each model
head(dd2)
#输出C指数结果
# Output C-index results
write.table(dd2,"output_C_index.txt", col.names = T, row.names = F, sep = "\t", quote = F)

# 这里原文仅看了GEO验证集的C指数均值，可以看到StepCox[forward] + lasso的模型组合在GEO验证集的平均C指数最高
# The original text only examined GEO validation set's mean C-index, showing StepCox[forward] + lasso had highest average C-index

### StepCox[forward] + lasso构建预测模型
### Build predictive model with StepCox[forward] + lasso
fit <- step(coxph(Surv(OS.time,OS)~., est_dd), direction = "forward")
multiCoxSum = summary(fit)
outTab = data.frame()
outTab = cbind(
  coef = multiCoxSum$coefficients[,"coef"],
  HR = multiCoxSum$conf.int[,"exp(coef)"],
  HR.95L = multiCoxSum$conf.int[,"lower .95"],
  HR.95H = multiCoxSum$conf.int[,"upper .95"],
  pvalue = multiCoxSum$coefficients[,"Pr(>|z|)"])
outTab <- as.data.frame(outTab)
outTab = cbind(id = row.names(outTab), outTab)

# 输出多因素cox结果
# Output multivariate Cox results
write.table(outTab, file = "output_multiCox.txt", sep = "\t", row.names = F, quote = F)

# 多因素cox并没有基因的剔除，因此用全部基因做lasso
# 这里不用卡P值，迭代的结果就是可以纳入的基因
# Multivariate Cox didn't exclude any genes, so using all genes for lasso
# No need to filter by p-value here, iteration results indicate includable genes
rid <- names(coef(fit)) 

# 训练集
# Training set
est_dd2 <- est_data[,c('OS.time', 'OS', rid)]

# 验证集
# Validation sets
val_dd_list2 <- lapply(val_data_list, function(x){x[,c('OS.time', 'OS', rid)]})

x1 <- as.matrix(est_dd2[,rid])
x2 <- as.matrix(Surv(est_dd2$OS.time, est_dd2$OS))
set.seed(seed)
fit = glmnet(x1, x2, family = "binomial", alpha = 1, lambda = NULL)
mypal <- pal_npg("nrc")(10)
开始画图
Plotting
图B - Lasso作图
Figure B - Lasso plot
pdf("A_lasso.pdf", width = 8, height = 6)
plot(fit, xvar = "dev", label = TRUE, lwd = 2, col = mypal, font.axis = 2,
     font.axis = 2,font.main = 2)
dev.off()
cvfit = cv.glmnet(x1, x2,
                  nfold = 10, 
                  family = "binomial",
                  type.measure = "class"
)
cvfit$lambda.min
myCoefs <- coef(cvfit, s = "lambda.min");
lasso_fea <- myCoefs@Dimnames[[1]][which(myCoefs != 0 )]
(lasso_fea <- lasso_fea[-1])
write.csv(lasso_fea,"output_feature_lasso.csv")

pdf("B_lasso.pdf", width = 8, height = 6)
plot(cvfit, lwd = 2, col = mypal, font.axis = 2,
     font.axis = 2, font.main = 2, font.sub = 2)
dev.off()
fit = cv.glmnet(x1, x2,
                nfold = 10, 
                family = "binomial", alpha = 1,
                type.measure = "class")

### 根据StepCox[forward] + lasso得到三个数据集每个样本的风险分数
### Calculate risk scores for each sample in three datasets using StepCox[forward] + lasso
rs <- lapply(val_dd_list2, function(x){cbind(x[,1:2], RS = as.numeric(predict(fit, type = 'response', newx = as.matrix(x[,-c(1,2)]), s = fit$lambda.min)))})
A_lasso.pdf可以把基因名标注在图上，方法可参考FigureYa31lasso
For A_lasso.pdf, gene names can be labeled on the plot. Refer to
FigureYa31lasso for method:
图A - C指数的热图
Figure A - Heatmap of C-indices
library(ComplexHeatmap)
library(circlize)
library(RColorBrewer)

# 根据C指数排序
# Sort by C-index value
dd2 <- dd2[order(dd2$GEO, decreasing = T),]

# 仅绘制GEO验证集的C指数热图
# Create heatmap data using only GEO validation sets' C-indices
dt <- dd2[, 3:4]
rownames(dt) <- dd2$Model
col_ha <- HeatmapAnnotation(which = "col", Cohort = c("GSE57303","GSE62254"),
                            annotation_name_gp = gpar(fontsize = 9, fontface = "bold"),
                            annotation_name_side = "left",
                            col = list(Cohort=c("GSE57303"="#00A087B2",
                                                "GSE62254"="#3C5488B2")),
                            annotation_legend_param = list(Cohort=list(title = "Cohort",
                                                                       title_position = "topleft",
                                                                       title_gp = gpar(fontsize = 12, fontface = "bold"),
                                                                       labels_rot = 0,
                                                                       legend_height = unit(1,"cm"),
                                                                       legend_width = unit(5,"mm"),
                                                                       labels_gp = gpar(fontsize = 9,
                                                                                        fontface = "bold"))
                                                           )
                            )
# 行注释
# Row annotations
row_ha <- rowAnnotation('Mean Cindex' = anno_barplot(round(rowMeans(dt), 3), bar_width = 1, add_numbers = T,
                                                     labels = c("Mean Cindex"), height = unit(1, "mm"),
                                                     gp = gpar(col = "white", fill = "skyblue1"), numbers_gp = gpar(fontsize = 8),
                                                     axis_param = list(at = c(0, 0.5, 1),
                                                                       labels = c("0", "0.5", "1")),
                                                     width = unit(2.5, "cm")),
                        annotation_name_side = "bottom",
                        annotation_name_gp = gpar(fontsize = 9, fontface = "bold", angle = 90))

# 自定义图形，主要是热图右侧的条形图
# Custom cell function to display values in heatmap cells
cell_fun <- function(j, i, x, y, width, height, fill) {
  grid.text(
    round(dt[i, j], 2), 
    x, y,
    gp = gpar(
      fontsize = 8
    ))
}

# 画出热图
# Generate heatmap
pdf("ComplexHeatmap.pdf", width = 10, height = 18)
heatmap <- Heatmap(dt,name = " ",
                   heatmap_legend_param = list(title="",title_position = "topleft", labels_rot = 0,
                                               legend_height = unit(8,"cm"),
                                               legend_width = unit(5,"mm"),
                                               labels_gp = gpar(fontsize = 15, fontface = "bold")),
                   border = TRUE,
                   column_split = c("GSE57303","GSE62254"),
                   column_gap = unit(3, "mm"),
                   show_column_names = F,
                   show_row_names = T,
                   col = colorRamp2(c(0.4,0.55,0.7), c("#4DBBD5B2", "white", "#E64B35B2")), 
                   column_title ="", 
                   #row_title ="Intersect Gene",
                   column_title_side = "top",
                   row_title_side = "left",
                   row_title_rot = 90, 
                   column_title_gp = gpar(fontsize = 12, fontface = "bold",col = "black"), 
                   #row_title_gp = gpar(fontsize = 15, fontface = "bold",col = "black"),
                   cluster_columns =F,
                   cluster_rows = F,
                   column_order = c(colnames(dt)),
                   show_row_dend = F, 
                   cell_fun = cell_fun,
                   top_annotation = col_ha,
                   right_annotation = row_ha
)
draw(heatmap)
dev.off()
图C - 模型比较
Figure C - Model Comparison
# 首先获取TCGA样本的StepCox[forward] + lasso模型的风险分数
# First get risk scores from StepCox[forward] + lasso model for TCGA samples
rs_tcga <- rs$TCGA
rs_GSE57303 <- rs$GSE57303
rs_GSE62254 <- rs$GSE62254
rownames(rs_tcga) <- tcga$sample
rownames(rs_GSE57303) <- GSE57303$sample
rownames(rs_GSE62254) <- GSE62254$sample
head(rs_tcga)
# 这里原文是与其他模型进行比较，其实就是在rs_tcga第四列开始加上每个样本在其他模型的风险分数
# 这里我们将每个数据集的4到10列随机生成一些数，作为样本在其他模型的风险分数
# The original text compares with other models by adding risk scores from other models
# Here we randomly generate numbers for columns 4-10 as risk scores from other models
for (i in 4:10) {
  rs_tcga[,i] <- runif(nrow(rs_tcga), min = 1, max = 10)
  names(rs_tcga)[i] <- paste0("Set", i)
}
for (i in 4:10) {
  rs_GSE57303[,i] <- runif(nrow(rs_GSE57303), min = 1, max = 10)
  names(rs_GSE57303)[i] <- paste0("Set", i)
}
for (i in 4:10) {
  rs_GSE62254[,i] <- runif(nrow(rs_GSE62254), min = 1, max = 10)
  names(rs_GSE62254)[i] <- paste0("Set", i)
}
### 这里的模型比较*号的意思是：其他模型的C指数与RS相比差异是否显著
### The asterisks in model comparison indicate whether C-index differences from RS are significant

### 第一步，计算模型的C指数
### Step 1: Calculate C-indices for each model

# 先将每种模型分别存入列表中
# Store each model's results in a list
list_tcga <- list(RS = rs_tcga[,c(1:2,3)], Set4 = rs_tcga[,c(1:2,4)],
                Set5 = rs_tcga[,c(1:2,5)], Set6 = rs_tcga[,c(1:2,6)],
                Set7 = rs_tcga[,c(1:2,7)], Set8 = rs_tcga[,c(1:2,8)],
                Set9 = rs_tcga[,c(1:2,9)], Set10 = rs_tcga[,c(1:2,10)])
cc_tcga <- data.frame(Cindex = sapply(list_tcga,function(x){as.numeric(summary(coxph(Surv(OS.time, OS)~., x))$concordance[1])}),
                      se = sapply(list_tcga,function(x){as.numeric(summary(coxph(Surv(OS.time, OS)~.,x))$concordance[2])})) %>%
  rownames_to_column('ID')

list_GSE57303 <- list(RS = rs_GSE57303[,c(1:2,3)], Set4 = rs_GSE57303[,c(1:2,4)],
                Set5 = rs_GSE57303[,c(1:2,5)], Set6 = rs_GSE57303[,c(1:2,6)],
                Set7 = rs_GSE57303[,c(1:2,7)], Set8 = rs_GSE57303[,c(1:2,8)],
                Set9 = rs_GSE57303[,c(1:2,9)], Set10 = rs_GSE57303[,c(1:2,10)])
cc_GSE57303 <- data.frame(Cindex = sapply(list_GSE57303, function(x){as.numeric(summary(coxph(Surv(OS.time, OS)~., x))$concordance[1])}),
                      se = sapply(list_GSE57303, function(x){as.numeric(summary(coxph(Surv(OS.time, OS)~., x))$concordance[2])})) %>%
  rownames_to_column('ID')

list_GSE62254 <- list(RS = rs_GSE62254[,c(1:2,3)], Set4 = rs_GSE62254[,c(1:2,4)],
                Set5 = rs_GSE62254[,c(1:2,5)], Set6 = rs_GSE62254[,c(1:2,6)],
                Set7 = rs_GSE62254[,c(1:2,7)], Set8 = rs_GSE62254[,c(1:2,8)],
                Set9 = rs_GSE62254[,c(1:2,9)], Set10 = rs_GSE62254[,c(1:2,10)])
cc_GSE62254 <- data.frame(Cindex = sapply(list_GSE62254, function(x){as.numeric(summary(coxph(Surv(OS.time, OS)~., x))$concordance[1])}),
                      se = sapply(list_GSE62254, function(x){as.numeric(summary(coxph(Surv(OS.time, OS)~., x))$concordance[2])})) %>%
  rownames_to_column('ID')

### 第二步，计算其他模型C指数与RS差异的显著性
### Step 2: Calculate significance of differences between other models' C-indices and RS
rt <- rs_tcga
tcga_compareC_p <- data.frame(Var = colnames(rt[, 4:10]), pval = c(1:length(colnames(rt[, 4:10]))))
for (i in colnames(rt[, 4:10])) {
  p <- compareC(rt$OS.time, rt$OS, rt$RS, rt[,i])$pval
  tcga_compareC_p[which(tcga_compareC_p$Var == i), 2] <- p
}
write.table(tcga_compareC_p,"output_TCGA_Cindex_p.txt", col.names = T, row.names = F, sep = "\t", quote = F)

rt <- rs_GSE57303
GSE57303_compareC_p <- data.frame(Var=colnames(rt[, 4:10]),pval=c(1:length(colnames(rt[, 4:10]))))
for (i in colnames(rt[, 4:10])) {
  p <- compareC(rt$OS.time, rt$OS, rt$RS, rt[, i])$pval
  GSE57303_compareC_p[which(GSE57303_compareC_p$Var == i), 2] <- p
}
write.table(GSE57303_compareC_p, "output_GSE57303_Cindex_p.txt", col.names = T, row.names = F, sep = "\t", quote = F)

rt <- rs_GSE62254
GSE62254_compareC_p <- data.frame(Var = colnames(rt[, 4:10]), pval = c(1:length(colnames(rt[, 4:10]))))
for (i in colnames(rt[, 4:10])) {
  p <- compareC(rt$OS.time, rt$OS, rt$RS, rt[,i])$pval
  GSE62254_compareC_p[which(GSE62254_compareC_p$Var == i), 2] <- p
}
write.table(GSE62254_compareC_p, "output_GSE62254_Cindex_p.txt", col.names = T, row.names = F, sep = "\t", quote = F)

### 第三步，将C指数，置信区间，差异显著性整合
### Step 3: Integrate C-indices, confidence intervals and significance

# 添加一行，使得两个数据可以直接合并
# Add a row so datasets can be merged directly
tcga_compareC_p <- rbind(c("RS", 1), tcga_compareC_p)
GSE57303_compareC_p <- rbind(c("RS", 1), GSE57303_compareC_p)
GSE62254_compareC_p <- rbind(c("RS", 1), GSE62254_compareC_p)

# 合并两个数据
# Merge the two datasets
all_tcga <- data.frame(cc_tcga, p = tcga_compareC_p[, 2])
all_GSE57303 <- data.frame(cc_GSE57303, p = GSE57303_compareC_p[, 2])
all_GSE62254 <- data.frame(cc_GSE62254, p = GSE62254_compareC_p[, 2])

### 第四步，画图
### Step 4: Plotting
dd <- all_tcga

# 将p值转换为*号
# Convert p-values to asterisks
dd$ll <- ifelse(dd$p < 0.0001, '****', ifelse(dd$p < 0.001, '***', ifelse(dd$p < 0.01, '**', ifelse(dd$p < 0.05, '*', ''))))
rownames(dd) <- NULL

ggplot(dd, aes(Cindex, reorder(ID, Cindex))) +
  geom_errorbarh(aes(xmax = Cindex + se, xmin = Cindex - se), color = "black", height = 0, size = 0.7) + 
  geom_point(size = 4, shape = 21, fill = pal_nejm()(10)[1]) + # 绘制点图
  ylab(NULL) + xlab(NULL) +
  labs(title ="TCGA") +
  geom_vline(xintercept = 0.6, linetype = 'dashed', size = 0.5, color = 'grey50') + 
  theme_bw(base_rect_size = 1) +
  theme(panel.grid = element_blank(),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 13),
        plot.title = element_text(hjust = 0.5, size = 15),
        legend.position = 'none',
        strip.text = element_text(size = 14)) + 
  geom_text(aes(x = 0.89, y = ID, label = ll), color = 'black', size = 3, vjust = 0.76) + 
  scale_x_continuous(breaks = c(0.5,0.7,0.9), limits = c(0.4, 0.94))
ggsave("tcga_model_compare.pdf", width = 6, height = 8)

# 在另外两个数据集中进行同样的操作
# Perform the same operation in the other two datasets
dd <- all_GSE57303
dd$ll <- ifelse(dd$p < 0.0001, '****', ifelse(dd$p < 0.001, '***', ifelse(dd$p < 0.01, '**', ifelse(dd$p < 0.05, '*', ''))))
rownames(dd) <- NULL

ggplot(dd, aes(Cindex, reorder(ID, Cindex))) +
  geom_errorbarh(aes(xmax = Cindex + se, xmin = Cindex - se), color = "black", height = 0, size = 0.7) +
  geom_point(size = 4, shape = 21, fill = pal_nejm()(10)[1]) +
  ylab(NULL) + xlab(NULL) +
  labs(title ="GSE57303") +
  geom_vline(xintercept = 0.6, linetype = 'dashed', size = 0.5, color = 'grey50') +
  theme_bw(base_rect_size = 1) +
  theme(panel.grid = element_blank(),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 13),
        plot.title = element_text(hjust = 0.5, size = 15),
        legend.position = 'none',
        strip.text = element_text(size = 14)) + 
  geom_text(aes(x = 0.89, y = ID, label = ll), color = 'black', size = 3, vjust = 0.76) +
  scale_x_continuous(breaks = c(0.5, 0.7, 0.9), limits = c(0.4, 0.94))
ggsave("GSE57303_model_compare.pdf", width = 6, height = 8)

dd <- all_GSE62254
dd$ll <- ifelse(dd$p < 0.0001, '****', ifelse(dd$p < 0.001, '***', ifelse(dd$p < 0.01, '**', ifelse(dd$p < 0.05, '*', ''))))
rownames(dd) <- NULL

ggplot(dd, aes(Cindex, reorder(ID, Cindex))) +
  geom_errorbarh(aes(xmax = Cindex + se, xmin = Cindex-se), color = "black", height = 0, size = 0.7) +
  geom_point(size = 4, shape = 21, fill = pal_nejm()(10)[1]) +
  ylab(NULL) + xlab(NULL) +
  labs(title ="GSE62254") +
  geom_vline(xintercept = 0.6, linetype = 'dashed', size = 0.5, color = 'grey50') +
  theme_bw(base_rect_size = 1) +
  theme(panel.grid = element_blank(),
        axis.text.y = element_text(size = 12),
        axis.text.x = element_text(size = 12),
        axis.title = element_text(size = 13),
        plot.title = element_text(hjust = 0.5, size = 15),
        legend.position = 'none',
        strip.text = element_text(size = 14)) + 
  geom_text(aes(x = 0.89, y = ID, label = ll), color = 'black', size = 3, vjust = 0.76) +
  scale_x_continuous(breaks = c(0.5,0.7,0.9), limits = c(0.4,0.94))
ggsave("GSE62254_model_compare.pdf", width = 6, height = 8)
Session Info
sessionInfo()