FigureYa130coxSVM_step34
FigureYa130SVM_step34
¶
小丫画图出品, 2025-5-20
Author: Yufang Wang
Reviewer: Ying Ge, Junyi Shen
第一步和第二步
¶
先打开FigureYa130coxSVM_step12.Rmd文件，运行第一步和第二步，生成的TCGA-LIHC-survival-relevant-DMP-matrix.csv文件作为本文档的输入文件，我把这个文件上传到微云，下载链接：
https://share.weiyun.com/5GsDqAM
。 Open the FigureYa130coxSVM_step12 first. RMD file, run the first and second steps, the generated TCGA-LIHC-survival-relevant-DMP-matrix.csv file as the input file of this document, I upload this file to Weiyun, download link: https://share.weiyun.com/5GsDqAM.
环境设置
¶
下载并安装Anaconda发行版，
https://www.anaconda.com/distribution/#download-section
Download and install the Anaconda distribution, https://www.anaconda.com/distribution/#download-section
里面已经包含了运行本文档所需的Python3、ipython、Jupyter notebook。 It already contains the Python3, ipython, and Jupyter notebooks required to run this document.
在终端运行以下命令来安装所需要的包： Run the following command in the terminal to install the required package:
pip install pandas
pip install sklearn
运行代码
¶
在python里运行下面的代码。
第三步，REF-SVM寻找合适的特征范围
¶
In [ ]:
import
pandas
as
pd
from
sklearn.model_selection
import
KFold
,
train_test_split
from
sklearn.feature_selection
import
RFE
from
sklearn.model_selection
import
cross_val_score
from
sklearn.svm
import
SVC
import
matplotlib.pyplot
as
plt
##生成映射字典
Generate a mapping dictionary
category_mapping
=
{
'High_risk'
:
3
,
'Inter_risk'
:
2
,
'Low_risk'
:
1
}
##以dataframe形式读入数据
Read data as a dataframe
differ_methyl_450_survival_df
=
pd
.
read_csv
(
"TCGA-LIHC-survival-relevant-DMP-matrix.csv"
,
sep
=
","
,
index_col
=
0
)
print
(
differ_methyl_450_survival_df
.
head
(
20
))
##转换并获取X，y值
Convert and get the X,y values
differ_methyl_450_survival
=
differ_methyl_450_survival_df
.
values
X
=
differ_methyl_450_survival
[:,
3
:]
y
=
differ_methyl_450_survival_df
[
'subtype'
]
.
map
(
category_mapping
)
y
=
y
.
astype
(
'int'
)
train_X
,
test_X
,
train_y
,
test_y
=
train_test_split
(
X
,
y
,
test_size
=
1
/
3
,
random_state
=
3
)
# 这里划分数据以1/3的来划分 训练集训练结果 测试集测试结果
Here, the data is divided into 1/3 of the training set training results and the test set test results
params
=
list
(
range
(
100
,
len
(
X
[
1
]),
100
))
print
(
"params:
%s
"
%
params
)
# 下面这步运行时间长，耐心等待
The following step takes a long time to run, so wait patiently
test_scores
=
[]
for
param
in
params
:
estimator
=
SVC
(
kernel
=
'linear'
)
selector
=
RFE
(
estimator
,
n_features_to_select
=
param
)
#这里没有使用KFold，直接使用cross_val_score的cv参数，代替KFold
KFold is not used here, just the cross_val_score cv parameter instead of KFold
##如果要使用KFold的话在这里写for循环
If you want to use KFold, write a for loop here
test_score
=
cross_val_score
(
selector
,
train_X
,
train_y
,
cv
=
10
,
scoring
=
'f1_macro'
)
#cv：选择每次测试折数  accuracy：评价指标是准确度,可以省略使用默认值
print
(
test_score
.
mean
())
test_scores
.
append
(
test_score
.
mean
())
##画出特征数量与f1_macro的值，寻找合适的特征数量范围
Draw the number of features and the values of the f1_macro to find a suitable range of feature numbers
plt
.
plot
(
params
,
test_scores
)
plt
.
xlabel
(
"Feature number"
)
plt
.
ylabel
(
"Cross validation"
)
plt
.
show
()
跑出来的部分数据 Some of the data that came out
In [ ]:
# [0.64       0.58333333 0.66666667 0.70833333 0.39130435 0.59090909
#  0.68181818 0.59090909 0.72727273 0.5       ]
# [0.68       0.625      0.58333333 0.70833333 0.56521739 0.5
#  0.63636364 0.63636364 0.77272727 0.68181818]
# [0.68       0.70833333 0.625      0.625      0.47826087 0.63636364
#  0.59090909 0.59090909 0.68181818 0.63636364]
# [0.64       0.66666667 0.625      0.625      0.43478261 0.63636364
#  0.68181818 0.59090909 0.72727273 0.63636364]
# [0.64       0.70833333 0.625      0.625      0.47826087 0.68181818
#  0.63636364 0.68181818 0.63636364 0.63636364]
# [0.64       0.70833333 0.625      0.625      0.60869565 0.59090909
#  0.68181818 0.63636364 0.63636364 0.63636364]
# [0.72       0.70833333 0.625      0.625      0.56521739 0.63636364
#  0.68181818 0.63636364 0.72727273 0.59090909]
# [0.68       0.75       0.625      0.54166667 0.60869565 0.59090909
#  0.68181818 0.63636364 0.63636364 0.59090909]
# [0.68       0.75       0.625      0.54166667 0.60869565 0.59090909
#  0.68181818 0.63636364 0.63636364 0.59090909]
# [0.68       0.70833333 0.625      0.625      0.65217391 0.63636364
#  0.68181818 0.59090909 0.63636364 0.59090909]
# [0.68       0.75       0.625      0.625      0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.70833333 0.625      0.625      0.60869565 0.59090909
#  0.68181818 0.59090909 0.63636364 0.59090909]
# [0.68       0.75       0.625      0.625      0.60869565 0.59090909
#  0.68181818 0.59090909 0.63636364 0.59090909]
# [0.68       0.75       0.625      0.625      0.60869565 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.72       0.75       0.58333333 0.625      0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.75       0.625      0.58333333 0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.70833333 0.625      0.625      0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.70833333 0.625      0.58333333 0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.70833333 0.625      0.54166667 0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.75       0.625      0.54166667 0.65217391 0.59090909
#  0.68181818 0.59090909 0.59090909 0.59090909]
# [0.68       0.75       0.625      0.54166667 0.65217391 0.63636364
#  0.68181818 0.59090909 0.59090909 0.59090909]
第四步，FW-SVM进一步细化特征数目
¶
In [ ]:
category_mapping
=
{
'High_risk'
:
3
,
'Inter_risk'
:
2
,
'Low_risk'
:
1
}
differ_methyl_450_survival_df
=
pd
.
read_csv
(
"TCGA-LIHC-survival-relevant-DMP-matrix.csv"
,
sep
=
","
,
index_col
=
0
)
# print(differ_methyl_450_survival_df.head(20))
differ_methyl_450_survival
=
differ_methyl_450_survival_df
.
values
print
(
differ_methyl_450_survival
[:
5
])
X
=
differ_methyl_450_survival
[:,
3
:]
y
=
differ_methyl_450_survival_df
[
'subtype'
]
.
map
(
category_mapping
)
y
=
y
.
astype
(
'int'
)
print
(
X
[:
5
])
print
(
y
[:
5
])
##根据REF-SVM的值，进一步细化特征数目范围
According to the value of REF-SVM, the range of the number of features is further refined
params
=
list
(
range
(
500
,
750
,
10
))
print
(
"params:
%s
"
%
params
)
test_scores
=
[]
X_train
,
X_test
,
y_train
,
y_test
=
train_test_split
(
X
,
y
,
test_size
=
1
/
3
,
random_state
=
3
)
X_train
=
preprocessing
.
scale
(
X_train
)
for
param
in
params
:
estimator
=
SVC
(
kernel
=
'linear'
)
selector
=
RFE
(
estimator
,
n_features_to_select
=
param
)
test_score
=
cross_val_score
(
selector
,
X_train
,
y_train
,
cv
=
10
,
scoring
=
"accuracy"
)
print
(
test_score
.
mean
())
test_scores
.
append
(
test_score
.
mean
())
plt
.
plot
(
params
,
test_scores
)
plt
.
xlabel
(
"Feature number"
)
plt
.
ylabel
(
"Cross validation"
)
plt
.
show
()
In [1]:
import
IPython
print
(
IPython
.
sys_info
())
!
jupyter nbconvert --to html FigureYa130coxSVM_step34.ipynb
In [ ]: