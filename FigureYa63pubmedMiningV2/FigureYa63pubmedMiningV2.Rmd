---
title: "FigureYa63PubmedMiningV2"
params:
  author: "Haitao Wang, Melvin L.K. Chua; Ying Ge, Yijing Chen"
output: html_document
---

**Author(s)**: `r params$author`  
**Date**: `r Sys.Date()`  


# Academic Citation
If you use this code in your work or research, we kindly request that you cite our publication:

Xiaofan Lu, et al. (2025). FigureYa: A Standardized Visualization Framework for Enhancing Biomedical Data Interpretation and Research Efficiency. iMetaMed. https://doi.org/10.1002/imm3.70005

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 需求描述
# Requirement description

通过API检索NCBI的Pubmed数据库，批量获得文章信息，整理出摘要里基因的词频。

NCBI's Pubmed database is searched through the API to obtain article information in bulk and organize the word frequencies of the genes in the abstracts.

# 应用场景
# Application scenario

- 老板交给我的这个基因好陌生，用这套代码跑出表格，一眼望去，发现它的好朋友我都很熟，于是，熟悉的思路、方法都能用上了。
- 文章做到第三部分卡住了，我的基因到底调控了谁，或者谁调控了它，或者它跟谁是好朋友一同发挥作用？用这套代码跑出表格，一眼望去，发现目的基因跟我熟悉的一类分子一同出现在某篇文章的摘要里，我们实验室有非常完善的研究这类分子的实验体系，接下来就瞄准这个分子了。

只要设置好检索词，就可以批量检索并整理文献和摘要，让你的头脑风暴比别人快10倍。

包含三个模块，相对独立，可分别运行。全部运行完将让你对目的基因有个整体的认识。

【模块一】文章的增长趋势

【模块二】发表了哪些文章

【模块三】**从摘要找好朋友**

- The gene my boss handed to me is quite unfamiliar. Using this set of code to generate a table, at a glance, I found that I am very familiar with its good friends, so I can apply familiar ideas and methods.

- The article got stuck at the third part. Exactly which gene is regulated by mine, or who regulates it, or with whom does it cooperate to function? Running this set of code to generate a table, at a glance, I found the target gene appearing alongside a familiar class of molecules in the abstract of a certain article. Our laboratory has a very comprehensive experimental system for studying this class of molecules, so the next step is to focus on this molecule.

As long as you set the search terms, you can batch search and organize the literature and abstracts, so that your brainstorming is 10 times faster than others.

It contains three modules that are relatively independent and can be run separately. All run through will give you an overall understanding of the target gene.

[Module 1] Trends in the growth of articles

[Module 2] What articles are published

[Module 3] **Find a good friend from the abstract**

# 环境设置
# Environment setting

```{r}
source("install_dependencies.R")

library(data.table)
library(stringr)
library(ggplot2)
library(rentrez) 
library(pubmed.mineR)
library(DT)
library(htmlwidgets)

Sys.setenv(LANGUAGE = "en") #显示英文报错信息 display English error messages
options(stringsAsFactors = FALSE) #禁止chr转成factor prohibit the conversion of chr to factor
```

# 输入文件
# Input file

## 常用词
## Common words

common_words_new.v2.txt，常用词。【模块三】计算词频时，要去除这些常用词。

common_words_new.v2.txt, common words. [Module 3] These common words are removed when calculating word frequency.

```{r}
common_words_new <- read.table("common_words_new.v2.txt")
common_words_new <- common_words_new$V1
```

## 基因名
## Gene name

每行一个基因。包含基因名、别名、位点，【模块三】将从摘要中统计这些基因名。还可以换成你想统计词频的其他类型的词。

One gene per row. It contains gene names, aliases, and loci. [Module 3] will count these gene names from the abstract. You can also replace them with other types of words for which you want to count frequency.  

```{r}
(load("HGNCdata.rda")) #位于当前文件夹 located in the current folder
head(HGNCdata)
```

# 参数设置
# Parameter setting

在这里设置检索词、检索的文章发表时间范围

set search terms and the publication time range of the retrieved articles here

```{r}
targetGene <- "PD-L1" #检索的基因名 retrieved gene names
year <- 2010:2018 #检索的文章的发表年份范围 the publication year range of the retrieved articles
```

这里用的检索词跟你在网页版Pubmed中用的检索词是一样的，初级用法就是用AND或OR连接你希望检索到的内容，例如基因名、疾病、处理、物种等。医学领域推荐直接用MeSH terme来限定，Medical Subject Headings(MeSH) refer to wiki <https://en.wikipedia.org/wiki/Medical_Subject_Headings>

如果用基因名作为检索词，建议把基因的别名都放进来，可以通过下面的代码提取：

The search terms used here are the same as those you would use in the web version of Pubmed, and the primary use is to connect what you wish to retrieve with AND or OR, such as gene name, disease, treatment, species, etc. In the medical field, it is recommended to directly use MeSH terms to specify, Medical Subject Headings(MeSH) refer to wiki <https://en.wikipedia.org/wiki/Medical_Subject_Headings>

If the gene name is used as a search term, it is recommended to put in all the aliases of the gene, which can be extracted by the following code:

```{r}
targetGene.Symbol <- HGNCdata[HGNCdata$Approved.Symbol %like% targetGene,]
targetGene.Synonyms <- HGNCdata[HGNCdata$Synonyms %like% targetGene,]
targetGeneInfo <- rbind(targetGene.Symbol, targetGene.Synonyms)
targetGeneInfo

term <- paste(as.character(targetGeneInfo$Approved.Symbol), str_replace_all(targetGeneInfo$Synonyms, ", ", " OR "), sep = " OR ")
term

# 还可以加上疾病的名字，例如GBM的MeSH term: Glioblastoma
# the name of the disease can also be added, e.g. GBM's MeSH term: Glioblastoma
#term <- paste0 ("(", term, ") AND Glioblastoma[MeSH Terms]")
#term

# 或者自己手写基因名作为检索词
# or handwrite your own gene name as a search term
#term <- "CD274 OR PD-L1 OR PDL1"
```

# 【模块一】文章的增长趋势
# [Module 1] Trends in the growth of articles

```{r}
#查询NCBI里的数据库简称
#query database abbreviations in NCBI
#entrez_dbs()
#pubmed里有哪些可以查询的fields
#what fields can be queried in PubMed?
#entrez_db_searchable(db = "pubmed")

#先写个函数，获取特定年份范围内发表的带有检索词的文章数量
#first write a function to get the number of articles with a search term published in a specific range of years
search_year <- function(year, term){
    query <- paste(term, "AND (", year, "[PDAT])")
    entrez_search(db="pubmed", term=query, retmax=0)$count
}

# 用前面“参数设置”里定义的检索词检索，文章越多，等的越久
# use the search terms defined in the previous "parameter setting" to search, the more articles you have, the longer you have to wait
papers <- sapply(year, search_year, term=term, USE.NAMES=FALSE) 

plot(year, papers, type='b', main="The PD-L1 papers")
```

# 【模块二】发表了哪些文章
# [Module 2] What articles are published

## 检索并从结果中提取出PMID、发表日期、文章名、期刊。
## Retrieve and extract the PMID, publication date, article name, and journal from the results.

```{r}
#我们先把retmax设为0，先不让它返回结果，这步只为了查看一共多少条记录
#let's set retmax to 0 and not let it return a result, just to see how many records there are
pre.result <- entrez_search(db="pubmed", term=term, retmode = "xml", retmax = 0)
pre.result$count #一共有多少条记录 how many records in total

#返回所有检索到的结果
#return all retrieved results
#result <- entrez_search(db="pubmed", term=term, retmode = "xml", retmax = pre.result$count)
#网速慢的话，先返回前200条记录
#if you have a slow internet connection, return the first 200 records first
result <- entrez_search(db="pubmed", term=term, retmode = "xml", retmax = 200)

#下载所有文件信息
#记录太多会被拒绝，因此每次提取200篇
#download all the paper info
#too many records will be rejected, so extract 200 articles each time
n <- 200 #每次读入的记录数量 number of records read each time
res <- c()
for (i in seq(1,length(result$ids),n)) {
  multi_summ <- entrez_summary(db="pubmed",id=result$ids[i:(i+n-1)])
  date_and_cite <- extract_from_esummary(multi_summ, c("uid","pubdate", "authors","title", "fulljournalname","elocationid"))
  res1 <- data.frame(t(date_and_cite))
  res1 <- data.frame(lapply(res1, as.character), stringsAsFactors=FALSE)
  res <- rbind(res,res1)
}

# 整理author name
# organize author name
tmp <- sub('^...............','', res$authors) # 如果想从左侧删除N个字符用 if you want to delete N characters from the left side, use
tmp <- gsub("\", \"", ", ", tmp)
tmp <- data.frame(sapply(tmp, function(x) unlist(strsplit(x,'\"'))[1]),stringsAsFactors = F)[,1]
tmp <- data.frame(sapply(tmp, function(x) unlist(strsplit(x,'"),'))[1]),stringsAsFactors = F)[,1]
tmp <- data.frame(sapply(tmp, function(x) unlist(strsplit(x,'",'))[1]),stringsAsFactors = F)[,1]
res$authors <- tmp

#把结果保存到文本文件
#save the results to a text file
write.table(res, "output_paper.txt", quote = F, sep = "\t", row.names = F)
```

## 添加文章的Pubmed链接，保存成网页格式
## Add the Pubmed link of the article, save it in web format

```{r}
uid <- res$uid
pubdate <- res$pubdate
pmcrefcount <- res$pmcrefcount
authors <- res$authors
title <- res$title
fulljournalname <- res$fulljournalname
elocationid <- res$elocationid

# 写个函数
# write a function
createLink <- function(base,val) {
  sprintf('<a href="%s" class="btn btn-link" target="_blank" >%s</a>',base,val)
}

# 按照网址规律给PMID和题目加上Pubmed链接
# add the Pubmed link to PMIDs and titles following the URL pattern
res <- data.frame(uid = createLink(paste0("https://www.ncbi.nlm.nih.gov/pubmed/?term=",uid),uid),
                  pubdate = pubdate, 
                  authors = authors,
                  title = createLink(paste0("https://www.ncbi.nlm.nih.gov/pubmed/?term=",uid),title),
                  fulljournalname = fulljournalname,
                  elocationid = elocationid,
                  stringsAsFactors = F)
res <- na.omit(res)
y <- DT::datatable(res,escape = F,rownames=F)

#保存到网页格式的文件
#save to web format file
DT::saveWidget(y,"output_paper.html")
```

# 【模块三】从摘要找好朋友
# [Module 3] **Find a good friend from the abstract***

## 检索
## Retrieve

这段检索跟前面“【模块二】发表了哪些文章”的开头一样，就不重复运行了。

This retrieval is the same as the beginning of "[Module 2] What articles are published", so it will not be run again.

```r
pre.result <- entrez_search(db="pubmed", term=term, retmode = "xml", retmax = 0)
pre.result$count 

#返回所有检索到的结果
#return all retrieved results
#result <- entrez_search(db="pubmed", term=term, retmode = "xml", retmax = pre.result$count)
#此处返回前200条记录
#return the first 200 records here
result <- entrez_search(db="pubmed", term=term, retmode = "xml", retmax = 200)
```

## 把xml文件整理成数据框格式
## Organize xml file into dataframe format

xml中包含title、authors、year、journal、key_words、doi、pmid、abstract等信息，整理成data.frame格式。

The xml contains information such as title, authors, year, journal, key_words, doi, pmid, abstract, etc., organized into the data.frame format.

```{r}
n <- 200 #每次读入的记录数量 number of records read each time
abstract0 <- c()
for (i in seq(1, length(result$ids), n)) {
  rec <- parse_pubmed_xml(entrez_fetch(db = "pubmed", id = result$ids[i : (i + n - 1)], rettype = "xml"))
  abstract1 <- as.data.frame(do.call('rbind', rec))
  abstract0 <- rbind(abstract0, abstract1)
}
abstract1[1,]

length(abstract1$abstract) # how many abstract 有多少摘要
abstract <- unlist(abstract0$abstract)

#查看其中某一篇文章的摘要
#view the abstract of one of the articles
#abstract[30]
```

## 提取abstract中的基因名，并统计出现频率。
## Extract the gene names in abstract and count the frequency of occurrence.

先把摘要分割成单个的单词，然后根据输入文件common_words_new.v2.txt去掉常用词，再根据HGNCdata.rda挑出基因名。

First, split the abstract into individual words, then remove common words according to the input file common_words_new.v2.txt, and finally extract gene names based on HGNCdata.rda.

```{r}
# 先用标点符号分割出单词
# split the word with punctuation first 
tempa <- unlist(strsplit(abstract, ",",fixed = T));
tempb <- unlist(strsplit(tempa, ":",fixed = T));
tempc <- unlist(strsplit(tempb, ";",fixed = T));
tempd <- unlist(strsplit(tempc, "'",fixed = T));
tempe <- unlist(strsplit(tempd, " ",fixed = T));
tempf <- unlist(strsplit(tempe, "/",fixed = T));
tempf <- unlist(strsplit(tempe, "\\|",fixed = T));
tempf <- unlist(strsplit(tempf, "(",fixed = T));
tempf <- unlist(strsplit(tempf, ")",fixed = T));
tempf <- unlist(strsplit(tempf, "-",fixed = T));
tempf <- unlist(strsplit(tempf, ".",fixed = T));

# 这里都转成大写字母，便于识别基因名，或者根据你自己的需要调整
# it's all capitalized here to make it easier to identify the gene name, or adjust it to your own needs
tempf <- toupper(tempf) 
tempi <- as.data.frame(table(tempf));

# 判断是不是常用词，如果是常用词，就删掉
# determine if it is a common word, and if it is a common word, delete it
tempj <- unlist(lapply(toupper(common_words_new), function(x){tempoo = which(as.character(tempi[,1]) == x); if (length(tempoo) != 0) return(tempoo)}));
tempk <- tempi[-tempj,];

# 根据Approved.Symbol挑出基因名
# select gene names based on Approved.Symbol
templ <- as.character(HGNCdata$Approved.Symbol);
head(templ)
# 有些物种的gene symbol里有小写字母，需要先转成大写，就运行下面这行
# some species have lowercase letters in their gene symbols that need to be converted to uppercase first, so run the following line
#templ <- toupper(templ)
tempm <- unlist(lapply(templ,function(x){return(which(x == as.character(tempk$tempf)))}));
tempn <- tempk[tempm,]

# 按照基因名出现频率排序
# sort by frequency of gene names
tempn2<- tempn[order(as.numeric(tempn$Freq), decreasing = T),]
tempo <- unlist(lapply(as.character(tempn2$tempf), function(x){return(which(x == templ))}));
Synonyms <- as.character(HGNCdata$Synonyms[tempo]);
data_table <- cbind.data.frame(Symbol=as.character(tempn2$tempf), Synonyms, Freq=as.numeric(tempn2$Freq));
colnames(data_table) <- c("Gene_symbol", "Synonyms", "Freq");

# 把基因名的出现频率保存到文件
# save the frequency of gene names to a file
write.table(data_table, "output_friends.txt", sep = "\t", quote = F, row.names = F)
```

## 给基因添加GeneCards链接，保存成网页格式
## Add GeneCards link to gene, save it in web format

```{r}
# 跟【模块二】一样的函数
# same function as [Module 2]
createLink <- function(base,val) {
  sprintf('<a href="%s" class="btn btn-link" target="_blank" >%s</a>',base,val)
}

# 根据GeneCards的网址规律，给基因名添加链接
# add links to gene names according to the URL pattern of GeneCards
res <- data.frame(symbols=createLink(paste0("https://www.genecards.org/cgi-bin/carddisp.pl?gene=",as.character(tempn2$tempf)),as.character(tempn2$tempf)),
                  Synonyms,
                  as.numeric(tempn2$Freq),
                  stringsAsFactors = F)
res <- na.omit(res)
y <- DT::datatable(res,escape = F,rownames=F)

#保存到网页格式的文件
#save to web format file
DT::saveWidget(y,"output_friends.html")
```

# 功能扩展
# Function expansion

【模块一】的文章数量可以借鉴时间数据的展示方式，画出酷炫的图；

【模块二】的结果可以添加影响因子；

【模块三】的结果可以画成词云。

享受吧！希望能帮助你加快研究进度！！！

The number of articles in [Module 1] can be visualized in a cool graph using time data display methods;

The results of [Module 2] can be added with impact factor;

The results of [Module 3] can be drawn as word clouds.

Enjoy it! Hope can help you speed up your research!!!

# 参考资料
# Reference

NCBI里的各种数据库，都可以用rentrez这个R包通过API访问，达到批量检索、处理的目的。

参考资料：<https://bioconnector.github.io/workshops/r-ncbi.html>

Various databases in NCBI can be accessed through API using the rentrez R package, achieving the purpose of batch retrieval and processing.

Reference: <https://bioconnector.github.io/workshops/r-ncbi.html>

# Session Info

```{r}
sessionInfo()
```